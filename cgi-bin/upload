#! /usr/bin/env python

import os
os.chdir("/home")

import cgi
import cgitb

cgitb.enable()
data = cgi.FieldStorage()

import imp
import json
import os
import subprocess

from os.path import join as pjoin

import scraperwiki.runlog; scraperwiki.runlog.setup()

def main():
    subprocess.call(['/home/tool/setup.sh'])


    # Send the browser back to the index page (the UI), and set ?uploaded
    # so that the javascript can tell what just happened.
    url = (os.environ["SERVER_NAME"] + 
           os.environ["REQUEST_URI"].replace("cgi-bin/upload", "http/"))

    print "Status: 302"
    print "Location: https://{0}?uploaded".format(url)

    # End of headers
    print

    path = pjoin("/home", "incoming", data["file"].filename)
    with open(path, "w") as fd:
       fd.write(data["file"].value)
       
    print "Hi, we've uploaded", path
    
    with open("/home/http/allSettings.json") as fd:
        all_settings = json.load(fd)

    # Discard .py extension
    module_name, _, _ = all_settings["filter"].partition(".")

    # Import the specified filter, without searching `sys.path`.
    module_info = imp.find_module(module_name, ["/home/tool/filter"])
    module = imp.load_module(module_name, *module_info)

    # Invoke its main() function with the path of the file to be processed
    module.main(path)

    scraperwiki.status('ok')
    

if __name__ == "__main__":
    main()
