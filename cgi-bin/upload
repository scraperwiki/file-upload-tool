#! /usr/bin/env python

import os
os.chdir("/home")

import scraperwiki
import scraperwiki.runlog
run_id = scraperwiki.runlog.setup()

import cgi

# (Enable these for debugging:)
# import cgitb
# cgitb.enable()

import imp
import json
import os
import subprocess
import datetime
import time

from os.path import join as pjoin

# Get data from the POST request
data = cgi.FieldStorage()

def main():

    # Install Python dependencies again
    # (just in case they've changed since last time)
    # We don't mind too much if this fails, since
    # the dependencies should already have been
    # installed by runSetup() in code.js
    subprocess.call(['/home/tool/setup.sh'])

    # Send the browser back to the index page (the UI), and set ?uploaded
    # so that the javascript can tell what just happened.
    url = (os.environ["SERVER_NAME"] +
           os.environ["REQUEST_URI"].replace("cgi-bin/upload", "http/"))

    # (Disable these for debugging:)
    print "Status: 302"
    print "Location: https://{0}?uploaded".format(url)

    # End of headers
    print

    file_name = data['file'].filename
    dir_name = str(int(time.time()))

    dir_path = pjoin('/home', 'http', dir_name)
    file_path = pjoin(dir_path, file_name)

    os.mkdir(dir_path)
    with open(file_path, 'w') as fd:
       fd.write(data['file'].value)

    print "Hi, we've uploaded", file_path

    scraperwiki.sql.save(['run_id'], {
        'run_id': run_id,
        'filename': file_name,
        'filepath': file_path,
        'datetime': datetime.datetime.utcnow(),
        'message': ''
    }, '_uploads')

    with open("/home/http/allSettings.json") as fd:
        all_settings = json.load(fd)

    # Discard .py extension
    module_name, _, _ = all_settings["filter"].partition(".")

    # Import the specified filter, without searching `sys.path`.
    module_info = imp.find_module(module_name, ["/home/tool/filter"])
    module = imp.load_module(module_name, *module_info)

    # Invoke its main() function with the path of the file to be processed
    message = module.main(file_path)

    scraperwiki.status('ok')
    scraperwiki.sql.execute('UPDATE _uploads SET message=? WHERE run_id=?', [message, run_id])
    scraperwiki.sql.commit()


if __name__ == "__main__":
    main()
